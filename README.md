# face-tracking
Implementing a Open CV based solution with addition of machine learning classifiers into a React.js web application. The candidates faces would move / change based on the face data. I’ve managed to hack this prototype together of an orange “Trump” head, with eyes following the user around and neck turning using 3D transforms for the “neck turning”

Lot’s of silly ideas come to mind with the web app, for example, we can

> have a boom box next to Trump’s head playing music from countries around the world, let’s say a French song comes on, we can make Donald Trump’s head start going from orange to red
> then he hits the boom box with his tiny hands all while following you’re every move. This is an area I could definitely use more help generating great ideas in, so please feel free to post something!!!

====================

# web-audio-api
( or simpler abstraction over the api )
Using the face tracking data stream, depending on where a person is in the frame while looking at the camera, Trump/Hillary will scream out different bits of hilarious audio.

=======================

# johnny-five
( Javascript Robotics )
The final step of the project is to create a robot Trump and Hillary which is essentially just hollow shells for the heads being turned by motors.

I'm aiming to relay the face tracking data to an Arduino or Raspberry Pi, which will then control a servo motor turning the heads depending on where the person is at the camera.

I would also like to incorporate a proximity sensor if possible so the robots shout different phrases at people on the street depending on how far away they are / almost prompting them to come closer to check out whats going on.